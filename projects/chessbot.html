<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ChessBot – Aidan Sussman</title>
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>
  <!-- Navigation -->
  <nav class="navbar">
    <div class="navbar-container">
      <a href="../index.html" class="logo">Aidan&nbsp;Sussman</a>
      <ul class="nav-links" id="nav-links">
        <li><a href="../index.html#about">About</a></li>
        <li><a href="../index.html#projects">Projects</a></li>
        <li><a href="../index.html#contact">Contact</a></li>
      </ul>
      <button class="nav-toggle" id="nav-toggle" aria-label="Toggle navigation">
        <span class="bar"></span>
        <span class="bar"></span>
        <span class="bar"></span>
      </button>
    </div>
  </nav>
  <!-- Hero section -->
  <header class="hero">
    <div class="hero-content">
      <h1>ChessBot</h1>
      <p>Programming a Sawyer robot arm to autonomously play chess.</p>
    </div>
  </header>
  <main class="container project-page" style="padding-top:2rem;">
    <h2>Project Goal</h2>
    <p>The aim of this EECS lab was to program the Sawyer robotic arm to play chess against a human opponent. The system detects the human’s moves, computes a response using the Stockfish engine and executes it autonomously.</p>
    <h2>Physical Design</h2>
    <p>To ensure reliable gripping, I designed and 3D‑printed uniform chess pieces and attached AR markers to the board and clock. These markers enabled camera‑based pose estimation for each square within the robot’s workspace.</p>
    <h2>Perception</h2>
    <p>Using ROS’s <code>ar_track_alvar</code> package, the vision system detected AR tags and computed the board’s pose. Board squares were mapped into the Sawyer arm’s coordinate frame for precise targeting.</p>
    <h2>Game Logic</h2>
    <p>A ROS node maintained the chess state. After each human move, a custom ROS service called the Stockfish engine to plan the robot’s response, ensuring legal and strategic moves.</p>
    <h2>Motion Planning &amp; Control</h2>
    <p>Piece and square commands were converted into joint trajectories using ROS MoveIt and an inverse‑kinematics solver. A custom‑tuned PID controller executed trajectories smoothly and accurately.</p>
    <h2>Results</h2>
    <p>The Sawyer robot successfully played full games of chess autonomously, moving its chosen pieces accurately and demonstrating seamless integration of perception, planning and control.</p>

    <!-- Extended discussion of kinematics, motion planning and control used to build ChessBot -->
    <h2>Forward Kinematics &amp; Coordinate Transformations</h2>
    <p>Before teaching the robot to play chess we first had to understand its geometry.  We implemented a <em>forward kinematics</em> function for a seven–degree–of–freedom arm.  Following the product‑of‑exponentials approach we defined a zero configuration and identified the screw axes (<code>ω<sub>i</sub></code>) and points <code>q<sub>i</sub></code> for each joint.  The homogeneous transform from the base to the tool frame was expressed as</p>
    <pre><code>def forward_kinematics(theta):
    """Compute gst(θ) for a 7‑DOF arm using the product of exponentials"""
    T = gst0  # transformation at zero configuration
    for i in range(7):
        w_i = omegas[i]          # joint axis ωᵢ
        q_i = qs[i]              # point on the axis qᵢ
        v_i = -np.cross(w_i, q_i) # linear velocity part
        twist = np.r_[w_i, v_i]   # screw axis ξᵢ
        T = T @ expm(skew(twist) * theta[i])
    return T
</code></pre>
    <p>This computation returns a 4×4 homogeneous matrix <code>gst(θ)</code> giving the end–effector pose for a vector of joint angles as described in Lab 3.  We verified our function against ROS’s built‑in tools by publishing joint state messages and comparing our output with <code>rosrun tf tf_echo base left_hand</code>.  To monitor coordinate frames dynamically we wrote a <em>transform listener</em> node using the tf2 library:</p>
    <pre><code>import rospy, tf2_ros
from geometry_msgs.msg import TransformStamped

tf_buffer = tf2_ros.Buffer()
tf_listener = tf2_ros.TransformListener(tf_buffer)
rate = rospy.Rate(10)
while not rospy.is_shutdown():
    try:
        trans = tf_buffer.lookup_transform("base", "right_gripper_tip", rospy.Time())
        print(trans.transform)
    except (tf2_ros.LookupException, tf2_ros.ExtrapolationException):
        continue
    rate.sleep()</code></pre>
    <p>This listener subscribes to tf topics and uses <code>tfBuffer.lookup_transform()</code> to return transforms between frames.  Catching <code>LookupException</code> and <code>ExtrapolationException</code> prevents our node from crashing.</p>

    <h2>Inverse Kinematics &amp; Pick‑and‑Place Planning</h2>
    <p>To move a chess piece the robot must determine joint angles that place the gripper at a desired square.  Inverse kinematics (IK) solves this problem.  We used the Sawyer SDK’s Position Kinematics service and the MoveIt motion planner to request IK solutions.  A Python script prompts the user for a target position and constructs a <code>SolvePositionIKRequest</code> message containing a <code>PoseStamped</code> with the desired position and a simple quaternion orientation (0, 1, 0, 0) so the gripper points straight down:</p>
    <pre><code>from geometry_msgs.msg import PoseStamped
from moveit_msgs.msg import RobotTrajectory
from intera_core_msgs.srv import SolvePositionIK, SolvePositionIKRequest

ik_service = rospy.ServiceProxy('/ExternalTools/right/PositionKinematicsNode/IKService',
                               SolvePositionIK)
req = SolvePositionIKRequest()
hdr = Header(stamp=rospy.Time.now(), frame_id='base')
pose = PoseStamped()
pose.header = hdr
pose.pose.position.x = 0.5
pose.pose.position.y = 0.5
pose.pose.position.z = 0.0
pose.pose.orientation.x = 0.0
pose.pose.orientation.y = 1.0
pose.pose.orientation.z = 0.0
pose.pose.orientation.w = 0.0
req.pose_stamp.append(pose)
res = ik_service(req)
joint_angles = dict(zip(res.joints.name, res.joints.position))
print(joint_angles)
</code></pre>
    <p>The solver returns a vector of joint angles that we then feed into our forward kinematics node to verify the pose, since IK may produce multiple solutions or fail if the pose is unreachable.  For the ChessBot, we recorded pick‑and‑place transforms using <code>rosrun tf tf_echo base right_gripper_tip</code> and created a <code>move_arm</code> node that invokes MoveIt’s IK and trajectory planning to move between the recorded poses while opening and closing the gripper.  Careful zero‑g positioning and use of ROS’s <code>intera_interface</code> library ensured safe operation of Sawyer’s hardware.</p>

    <h2>Path Planning &amp; Feedback Control</h2>
    <p>Computing IK positions is only part of the puzzle.  To move from one configuration to another without collisions or abrupt motion, we used MoveIt’s path planner.  The MoveIt GUI allowed us to set start and goal states by dragging the Sawyer end effector and compute smooth trajectories.  For programmatic control, we interfaced with the <code>move_group</code> action server: an action client sends a goal containing the start state, goal state and optional constraints; the server returns a trajectory and publishes feedback as the arm moves.  Below is a simplified example of sending a path planning request using the <code>moveit_commander</code> wrapper:</p>
    <pre><code>from moveit_commander import MoveGroupCommander

group = MoveGroupCommander('right_arm')
group.set_pose_target([0.6, 0.2, 0.2, 0.0, 1.0, 0.0, 0.0])  # x,y,z,qx,qy,qz,qw
plan = group.plan()
group.execute(plan, wait=True)
</code></pre>
    <p>MoveIt can also accept orientation constraints and avoid obstacles by adding collision objects to the planning scene.  For example, we created a box representing the table and a virtual wall in the robot’s workspace and observed how the planner adjusted trajectories to avoid them.  After planning, execution can be delegated to MoveIt’s built‑in controllers or replaced with a custom controller.</p>
    <p>To study control strategies we implemented a feed‑forward velocity controller and then added proportional–derivative (PD) and proportional–integral–derivative (PID) feedback.  The controller receives a <code>moveit_msgs/RobotTrajectory</code> and updates the arm’s joint velocities according to</p>
    <pre><code># Compute control torques for one timestep
error = q_des - q
d_error = (error - prev_error) / dt
integral += error * dt
u = u_ff + Kp * error + Kd * d_error + Ki * integral
prev_error = error
</code></pre>
    <p>The proportional term drives the error towards zero, the derivative term damps oscillations and the integral term compensates for steady‑state errors.  Implementing the PID controller improved ChessBot’s tracking accuracy compared to the open‑loop and PD controllers.  By combining motion planning with feedback control, the robot executed smooth, reliable trajectories even when disturbances and modeling errors were present.</p>
    <!-- Media section showcasing images, diagrams and a demo video -->
    <h2>Media</h2>
    <p>Below you’ll find a selection of images, diagrams and a demonstration video that illustrate the ChessBot hardware, software architecture and control algorithms. Once you upload the actual photos to the repository’s <code>images/chessbot</code> folder (using the same filenames), they will automatically replace the placeholders shown here.</p>

    <!-- System architecture diagram -->
    <h3>System Architecture</h3>
    <div class="media-grid">
      <div>
        <img src="../images/chessbot/architecture_diagram.png" alt="High‑level system architecture showing the perception module feeding into the main logic, which communicates with the chess engine and controller">
        <p class="caption">High‑level software architecture: perception feeds into the main logic, which communicates with the chess engine and controller.</p>
      </div>
    </div>

    <!-- Hardware photos -->
    <h3>Hardware Setup</h3>
    <div class="media-grid">
      <div>
        <img src="../images/chessbot/board_setup.png" alt="Chess board set up for the ChessBot with custom 3D printed pieces and calibration markers">
        <p class="caption">Chess board set up with custom uniform pieces and calibration markers.</p>
      </div>
      <div>
        <img src="../images/chessbot/sawyer_robot.png" alt="The Sawyer robot arm poised over the chessboard, equipped with a gripper for moving pieces">
        <p class="caption">Sawyer robot arm equipped with a custom gripper, positioned over the playing board.</p>
      </div>
      <div>
        <img src="../images/chessbot/gripper_design.png" alt="3D printed gripper used by the ChessBot to grasp chess pieces securely">
        <p class="caption">3D‑printed gripper design used for reliable piece manipulation.</p>
      </div>
    </div>

    <!-- Perception and calibration images -->
    <h3>Vision &amp; Calibration</h3>
    <div class="media-grid">
      <div>
        <img src="../images/chessbot/difference_vectors.png" alt="Image showing AprilTag markers on the board with x and y difference vectors used for calibration">
        <p class="caption">AprilTag markers and difference vectors used to calibrate the board frame to the robot.</p>
      </div>
      <div>
        <img src="../images/chessbot/aruco_markers_grid.png" alt="Grid of ArUco/AprilTag patterns used for robust board pose estimation">
        <p class="caption">Grid of calibration tags used for accurate pose estimation.</p>
      </div>
    </div>

    <!-- Chess engine and control diagrams -->
    <h3>Chess Engine &amp; Control</h3>
    <div class="media-grid">
      <div>
        <img src="../images/chessbot/stockfish_icon.png" alt="Illustration of a fish on a chess square symbolizing the Stockfish engine">
        <p class="caption">The open‑source Stockfish engine computes the robot’s moves.</p>
      </div>
      <div>
        <img src="../images/chessbot/pid_block_diagram.png" alt="Block diagram of a PID controller showing proportional, integral and derivative blocks feeding into a summation">
        <p class="caption">PID control loop ensures smooth and precise execution of planned trajectories.</p>
      </div>
    </div>

    <!-- Video demonstration -->
    <h3>Video Demonstration</h3>
    <p>A short demonstration video showcases the ChessBot playing a game against a human opponent. The video file <code>chessbot-demo.mp4</code> has been uploaded to the repository root; it is embedded below and will autoplay, loop and mute by default. If you prefer to host the file in a <code>videos</code> folder, update the <code>src</code> path accordingly.</p>
    <div class="media-grid">
      <div>
        <video src="../chessbot-demo.mp4" controls autoplay muted loop>
          Your browser does not support the video tag.
        </video>
        <p class="caption">ChessBot demo: the robot plays a game against a human opponent.</p>
      </div>
    </div>
  </main>
  <footer class="footer" style="background-color:#f5f7fa;padding:2rem 0;margin-top:2rem;">
    <div class="container">
      <p>If you’d like to discuss this project or collaborate, please reach out at <a href="mailto:aidan.sussman@berkeley.edu">aidan.sussman@berkeley.edu</a>.</p>
    </div>
  </footer>
  <script src="../js/script.js"></script>
</body>
</html>
